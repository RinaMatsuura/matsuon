import streamlit as st
import tempfile
from openai import OpenAI
import os
import numpy as np
import soundfile as sf  # soundfileã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# ãƒšãƒ¼ã‚¸è¨­å®šã‚’è¡Œã†
st.set_page_config(
    page_title="æ¾æµ¦ã®å®Ÿé¨“ãƒšãƒ¼ã‚¸",
    page_icon="ğŸ§Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

def split_audio_file(file_path, chunk_length=60):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ãŸé•·ã•ï¼ˆç§’ï¼‰ã§åˆ†å‰²ã™ã‚‹"""
    try:
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        data, sample_rate = sf.read(file_path)  # soundfileã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        # åˆ†å‰²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        split_files = []
        total_samples = len(data)
        chunk_samples = chunk_length * sample_rate  # ãƒãƒ£ãƒ³ã‚¯ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        
        for i in range(0, total_samples, chunk_samples):
            chunk = data[i:i + chunk_samples]  # ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
            chunk_file_path = f"{file_path}_part{i // sample_rate}.wav"  # åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            sf.write(chunk_file_path, chunk, sample_rate)  # åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            split_files.append(chunk_file_path)  # åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã«è¿½åŠ 
        
        return split_files  # åˆ†å‰²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    except Exception as e:
        st.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []

st.title("éŸ³å£°æ–‡å­—èµ·ã“ã— ğŸ¤")

# ãƒšãƒ¼ã‚¸å†…ã§è¨€èªé¸æŠ
st.subheader("æ–‡å­—èµ·ã“ã—ã®è¨€èªã‚’é¸æŠ")
language = st.selectbox(
    "è¨€èªã‚’é¸æŠã—ã¦ãã ã•ã„",
    ["æ—¥æœ¬èª", "è‹±èª", "è‡ªå‹•æ¤œå‡º"],
    index=0
)

language_code = {
    "æ—¥æœ¬èª": "ja",
    "è‹±èª": "en",
    "è‡ªå‹•æ¤œå‡º": None
}

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®šç¾©
prompt = """
ã‚ãªãŸã¯ä¼šè©±æ–‡ã®æ•´ç†ã¨æ–‡å­—èµ·ã“ã—ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã£ã¦ä¼šè©±ã‚’æ•´ç†ã—ã¦ãã ã•ã„ï¼š

## å¿…é ˆã‚¿ã‚¹ã‚¯
1. è¤‡æ•°ã®è©±è€…ã®ç™ºè¨€ã‚’æ˜ç¢ºã«åŒºåˆ¥ã—ã¦è¨˜è¼‰ã—ã¦ãã ã•ã„
2. å…¨ã¦ã®éŸ³å£°ã‚’æ¼ã‚Œãªãå…¨ã¦è¨˜è¼‰ã—ã¦ãã ã•ã„
3. ä¼šè©±ãŒç™ºç”Ÿã—ãŸæ™‚é–“ï¼ˆåˆ†ï¼šç§’ï¼‰ã‚’ç™ºè©±ã”ã¨ã«è¨˜è¼‰ã—ã¦ãã ã•ã„
4. ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

### ä¼šè©±ãƒ­ã‚°
ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼A(åˆ†ï¼šç§’)ï¼šç™ºè¨€å†…å®¹
ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼B(åˆ†ï¼šç§’)ï¼šç™ºè¨€å†…å®¹
ï¼ˆæ™‚ç³»åˆ—é †ï¼‰

## å‡ºåŠ›å½¢å¼
- è©±è€…ã®åŒºåˆ¥ã¯ã€Œè©±è€…åï¼šã€ã®å½¢å¼ã§æ˜ç¤º
- æ™‚ç³»åˆ—é †ã«ä¼šè©±ã‚’è¨˜è¼‰
- ç®‡æ¡æ›¸ãã§è¦‹ã‚„ã™ãæ•´å½¢
"""

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®è¿½åŠ 
uploaded_file = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['mp3', 'm4a', 'wav'])

if uploaded_file is not None:
    with st.spinner("æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œä¸­..."):
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as temp_file:
            temp_file.write(uploaded_file.getvalue())
            temp_file_path = temp_file.name

        try:
            client = OpenAI()

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²
            split_files = split_audio_file(temp_file_path, chunk_length=60)  # 60ç§’ã”ã¨ã«åˆ†å‰²

            # Whisper APIã‚’ä½¿ç”¨ã—ã¦æ–‡å­—èµ·ã“ã—
            st.subheader("ğŸ” ä¼šè©±ã®åˆ†æ")
            all_transcriptions = []  # ã™ã¹ã¦ã®æ–‡å­—èµ·ã“ã—çµæœã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ

            for split_file in split_files:
                with open(split_file, "rb") as audio_file:
                    transcription = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language=language_code[language],
                        response_format="verbose_json"
                    )
                    all_transcriptions.append(transcription['segments'])  # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—çµæœã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 

            # ã™ã¹ã¦ã®æ–‡å­—èµ·ã“ã—çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¦è¡¨ç¤º
            st.write("### ä¼šè©±ãƒ­ã‚°:")
            for idx, segments in enumerate(all_transcriptions):
                for segment in segments:
                    start_time = segment['start']  # ç™ºè¨€ã®é–‹å§‹æ™‚é–“
                    text = segment['text']  # ç™ºè¨€å†…å®¹
                    speaker = "ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼A" if idx % 2 == 0 else "ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼B"  # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚’äº¤äº’ã«è¨­å®š
                    minutes = int(start_time // 60)
                    seconds = int(start_time % 60)
                    st.write(f"{speaker}({minutes}:{seconds:02d}): {text}")  # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã¨ã—ã¦è¡¨ç¤º

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)

# ä½¿ã„æ–¹ã®èª¬æ˜ã‚’æ›´æ–°
with st.expander("ğŸ’¡ ä½¿ã„æ–¹"):
    st.write("""
    1. ãƒšãƒ¼ã‚¸å†…ã§æ–‡å­—èµ·ã“ã—ã®è¨€èªã‚’é¸æŠ
    2. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆmp3, m4a, wavï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    3. è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ãŒé–‹å§‹ã•ã‚Œã¾ã™
    4. GPT-4ã«ã‚ˆã‚‹ä¼šè©±ã®åˆ†æçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    
    æ³¨æ„äº‹é …ï¼š
    - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ä¸Šé™ã¯100MB
    - å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: MP3, M4A, WAV
    - éŸ³å£°ã¯æ˜ç­ãªã‚‚ã®ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™
    """)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.sidebar.markdown("---")
st.sidebar.write("ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 1.0.0")
st.sidebar.write("Â© 2024 ã¾ã¤ã‚Šãª")

